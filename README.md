ğŸ§  Credit Card Fraud Detection â€” Projekt edukacyjny

ğŸ¯ Cel projektu

Celem projektu jest wykrywanie transakcji fraudowych (oszustw kartowych) z wykorzystaniem klasycznych modeli uczenia maszynowego.
Projekt zostaÅ‚ wykonany w ramach nauki metod klasyfikacji i analizy niezrÃ³wnowaÅ¼onych danych (ang. imbalanced data).

Priorytetem oceny modeli byÅ‚o zwiÄ™kszenie Recall (czuÅ‚oÅ›ci), czyli minimalizacja liczby bÅ‚Ä™dnie sklasyfikowanych oszustw (False Negative).

ğŸ“Š Opis danych

W projekcie wykorzystano publiczny zbiÃ³r danych z transakcjami kartowymi:

KaÅ¼da obserwacja reprezentuje pojedynczÄ… transakcjÄ™ z oznaczeniem 0 (transakcja prawidÅ‚owa) lub 1 (oszustwo).

Charakterystyka:

Dane silnie niezrÃ³wnowaÅ¼one â€” liczba fraudÃ³w stanowi poniÅ¼ej 0.2% wszystkich przypadkÃ³w,

Cechy zostaÅ‚y wczeÅ›niej przeksztaÅ‚cone metodÄ… PCA (anonimizacja danych finansowych),

Zmienna celu: Class

0 â†’ normalna transakcja

1 â†’ fraud

âš™ï¸ Zastosowane metody

W projekcie zaimplementowano i porÃ³wnano kilka klasyfikatorÃ³w:

Model	Resampling	Hiperparametryzacja	Metryka gÅ‚Ã³wna
Logistic Regression	SMOTE	RandomizedSearchCV	Recall
K-Nearest Neighbors (KNN)	SMOTE	GridSearchCV	Recall
Decision Tree	SMOTE	RandomizedSearchCV	Recall

Dodatkowo przetestowano warianty z parametrem class_weight='balanced'.

ğŸ§© Przebieg pracy

Eksploracja danych (EDA) â€“ analiza rozkÅ‚adÃ³w i zrÃ³wnowaÅ¼enia klas.

PodziaÅ‚ na zbiory train/test (stratyfikowany split).

Resampling danych metodÄ… SMOTE â€“ tylko wewnÄ…trz foldÃ³w walidacji (bez â€leakuâ€).

Uczenie modeli bazowych:

Logistic Regression,

KNN,

Decision Tree.

Hiperparametryzacja (GridSearchCV / RandomizedSearchCV).

Ewaluacja modeli:

macierze pomyÅ‚ek,

metryki (Precision, Recall, F1-score, ROC-AUC, PR-AUC).

PorÃ³wnanie wynikÃ³w i wnioski.


ğŸ§  Wnioski

W przypadku niezrÃ³wnowaÅ¼onych danych kluczowe jest uÅ¼ycie SMOTE lub waÅ¼enia klas.

Sama dokÅ‚adnoÅ›Ä‡ (accuracy) nie nadaje siÄ™ do oceny â€” zamiast tego uÅ¼yto Recall i PR-AUC.

Hiperparametryzacja (np. RandomizedSearchCV) poprawia wyniki o kilka punktÃ³w procentowych.

Modele drzewiaste majÄ… tendencjÄ™ do przeuczenia, dlatego stosowano ograniczenia (max_depth, ccp_alpha).
ğŸ“Œ GÅ‚Ã³wny wniosek: model regresji logistycznej z class_weight='balanced' i dobranym C najlepiej wykrywa fraudy, mimo niskiej precyzji.

ğŸ“š Dalsze kroki

PrzetestowaÄ‡ modele ensemble: Random Forest, XGBoost, LightGBM

DodaÄ‡ automatyczny raport w formacie .pdf

SprÃ³bowaÄ‡ oversamplingu metodÄ… ADASYN

PrzeprowadziÄ‡ analizÄ™ wpÅ‚ywu progu decyzyjnego (threshold tuning)  
